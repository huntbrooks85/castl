{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ðŸ§ ELFCASTL ðŸ§**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **âœ¨ Input Requirements âœ¨**\n",
    "### ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Full Directory Path for Input Spectrum (WAVELENGTH, FLUX, NOISE)\n",
    "input_file = '/Users/hunter_brooks8/Desktop/Accident.csv'\n",
    "\n",
    "# Input outfile file name (DO NOT PUT DIRECTORY OR FILETYPE)\n",
    "output_file = 'Accident'\n",
    "\n",
    "# Set the number of walkers\n",
    "walkers = 28\n",
    "\n",
    "# Set the number of steps\n",
    "steps = 2500\n",
    "\n",
    "# Set the number of discards\n",
    "discard = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports All Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports all required packages \n",
    "import emcee\n",
    "import corner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import LinearNDInterpolator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loads in Observational Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in the observed spectrum into SPLAT\n",
    "observed = pd.read_csv(input_file)\n",
    "\n",
    "# Gets the observed wavelength\n",
    "observed_wave = observed.iloc[:, 0].tolist()\n",
    "\n",
    "# Gets the observed fluxes\n",
    "observed_flux = observed.iloc[:, 1].tolist()\n",
    "observed_flux = [x / np.nanpercentile(observed_flux, 99.9) for x in observed_flux]\n",
    "observed_flux = [x if x >= 0 else 2.2250738585072014e-30 for x in observed_flux]\n",
    "observed_flux = np.nan_to_num(observed_flux, nan=2.2250738585072014e-30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Records All Spectral Grid Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# States all grid points\n",
    "grid_teff = [500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400]\n",
    "grid_logg = [4, 4.25, 4.5, 4.75, 5, 5.25, 5.5]\n",
    "grid_metal = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "grid_co = [0.5, 1.0, 1.5, 2.5]\n",
    "grid_kzz = [2, 4, 7, 8, 9]\n",
    "total_grid = {'Teff': [], 'logg': [], 'metallicity': [], 'C/O': [], 'log(kzz)': [], 'wavelength': [], 'flux': []}\n",
    "\n",
    "# Records all grid points and the wavelength \n",
    "for i in range(len(grid_teff)):\n",
    "    for j in range(len(grid_logg)): \n",
    "        for p in range(len(grid_metal)): \n",
    "            for l in range(len(grid_co)): \n",
    "                for h in range(len(grid_kzz)): \n",
    "                    lower_metal = grid_metal[p]\n",
    "                    if lower_metal == 0.0: \n",
    "                        lower_metal = -0.00\n",
    "                    model_name = f'/Volumes/HUNTER/BONES/SPECTRA/MODELS/ELFOWL/elfowl24_t{grid_teff[i]:.0f}_g{grid_logg[j]:.2f}_z{lower_metal:.2f}_kzz{grid_kzz[h]:.2f}_co{grid_co[l]:.2f}_CUSTOM.txt'\n",
    "                    data = pd.read_csv(model_name, delimiter='\\t')\n",
    "                    \n",
    "                    wave = np.array(data['wave'])  # Convert to numpy array\n",
    "                    flux = np.array(data['flux'])  # Convert to numpy arra\n",
    "                    \n",
    "                    f_interp = interp1d(wave, flux, kind='linear', fill_value=\"extrapolate\")\n",
    "                    resampled_flux = f_interp(observed_wave)\n",
    "                    percentile_999 = np.nanmax(resampled_flux)\n",
    "                    resampled_flux /= percentile_999\n",
    "        \n",
    "                    total_grid['Teff'].append(grid_teff[i])                # Add a new Teff value\n",
    "                    total_grid['logg'].append(grid_logg[j])                # Add a new logg value\n",
    "                    total_grid['metallicity'].append(grid_metal[p])        # Add a new metallicity value\n",
    "                    total_grid['C/O'].append(grid_co[l])                   # Add a new C/O ratio value\n",
    "                    total_grid['log(kzz)'].append(grid_kzz[h])             # Add a new log(kzz) value\n",
    "                    total_grid['wavelength'].append(wave)                  # Overwrite the wavelength data\n",
    "                    total_grid['flux'].append(resampled_flux)                        # Add flux data for the new set of parameters             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes the total grid and fluxes and then makes an interpolation grid\n",
    "point_grid = []\n",
    "for i in range(len(total_grid['Teff'])): \n",
    "    point_grid.append([total_grid['Teff'][i], total_grid['logg'][i], total_grid['metallicity'][i], total_grid['C/O'][i], total_grid['log(kzz)'][i]])\n",
    "point_grid = np.array(point_grid)\n",
    "value_grid = np.array(total_grid['flux'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Test Function AND Interpolation Between Grid Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounds to the nearest hundred\n",
    "def closest_hundreds(value):\n",
    "    lower_hundred = (value // 100) * 100\n",
    "    upper_hundred = lower_hundred + 100\n",
    "    return lower_hundred, upper_hundred\n",
    "\n",
    "# Rounds to the nearest half\n",
    "def closest_bounds(target, numbers):\n",
    "    lower_bound = max(num for num in numbers if num <= target)\n",
    "    upper_bound = min(num for num in numbers if num >= target)\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Defines the chi^2 statistical approach for our MCMC simulation\n",
    "def rsquare(observed_wave, observed_flux, parm, total_grid): \n",
    "    # Loads in the model spectrum\n",
    "    target_co = [0.5, 1.0, 1.5, 2.5]\n",
    "    target_kzz = [2, 4, 7, 8, 9]\n",
    "    target_logg = [4, 4.25, 4.5, 4.75, 5, 5.25, 5.5]\n",
    "    target_metal = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "    grid_parm = [\n",
    "        *closest_hundreds(parm[0]),\n",
    "        *closest_bounds(parm[1], target_logg),\n",
    "        *closest_bounds(parm[2], target_metal),\n",
    "        *closest_bounds(parm[3], target_co),\n",
    "        *closest_bounds(parm[4], target_kzz)\n",
    "    ]\n",
    "    \n",
    "    bounds = np.array([\n",
    "        [int(grid_parm[0]), grid_parm[2], grid_parm[4], grid_parm[6], grid_parm[8]],\n",
    "        [int(grid_parm[1]), grid_parm[3], grid_parm[5], grid_parm[7], grid_parm[9]]\n",
    "    ])\n",
    "    \n",
    "    # Define grid points\n",
    "    grid_points = np.array([\n",
    "        [temp, logg, metal, co, kzz]\n",
    "        for temp in bounds[:, 0]\n",
    "        for logg in bounds[:, 1]\n",
    "        for metal in bounds[:, 2]\n",
    "        for co in bounds[:, 3]\n",
    "        for kzz in bounds[:, 4]\n",
    "    ])\n",
    "    \n",
    "    indices = np.array([np.where(np.all(point_grid == point, axis=1))[0][0] for point in grid_points])\n",
    "    model_fluxes = value_grid[indices]\n",
    "    \n",
    "    model_flux = griddata(grid_points, model_fluxes, (parm[0], parm[1], parm[2], parm[3], parm[4]), method='linear', rescale=True)\n",
    "\n",
    "    # Performs the chi square calculations and returns it\n",
    "    observed_flux = np.array(observed_flux)\n",
    "    model_flux = np.array(model_flux)\n",
    "    \n",
    "    # Normalize model flux to match the observed flux sum\n",
    "    squared_differences = np.square(np.subtract(model_flux, observed_flux))\n",
    "    mean_squared_difference = np.nanmean(squared_differences)\n",
    "    rmse = np.sqrt(mean_squared_difference)\n",
    "    \n",
    "    return -10000*rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Makes the Parameter Space and Verifies the Walkers are Going in the Correct Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines MCMC priors\n",
    "def prior(parm):\n",
    "    a, b, c, d, e, f, g = parm\n",
    "    if 500 < a < 2400 and 4 < b < 5.5 and -1.0 < c < 0.5 and 0.5 < d < 2.5 and 2 < e < 9 and -0.2 < f < 0.2 and -0.001 < g < 0.001:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "# Defines the MCMC posteriors\n",
    "def log_posterior(parm):\n",
    "    lp = prior(parm)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + rsquare(observed_wave, observed_flux, parm, total_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up the MCMC Code Using the EMCEE Package (MAY TAKE A COUPLE OF MINUTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2500/2500 [05:33<00:00,  7.50it/s]\n"
     ]
    }
   ],
   "source": [
    "  # Runs the MCMC simulation #\n",
    "# ------------------------------------------------------------ #\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ndim, nwalkers = 7, walkers\n",
    "    n_steps = steps\n",
    "\n",
    "    initial_positions = np.random.uniform(low=[1000, 5, -0.5, 0.5, 2, -0.05, -0.001], \n",
    "                                        high=[2000, 5.25, 0.5, 1.0, 8, 0.05, 0.001], \n",
    "                                        size=(nwalkers, ndim))\n",
    "\n",
    "    with Pool() as pool:\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior, pool=pool)\n",
    "        sampler.run_mcmc(initial_positions, n_steps, progress=True)\n",
    "# ------------------------------------------------------------ #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finds the Best Values and the Errors From the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--------------------------------------------------------------------------------------------------------#\n",
      "                     Best Fit Parameters Ï‡2 = 0.236\n",
      "#--------------------------------------------------------------------------------------------------------#\n",
      "  Best Fit Parameters: Teff = 501.9K, log(g) = 5.474cmâ„s^2, [M/H] = -0.999, C/O = 0.607, log(Kzz) = 2.47\n",
      "#--------------------------------------------------------------------------------------------------------#\n",
      "    Lower Estimate: Teff = 500.2K, log(g) = 5.436cmâ„s^2, [M/H] = -1.0, C/O = 0.542, log(Kzz) = 2.028\n",
      "    Upper Estimate: Teff = 507.2K, log(g) = 5.497cmâ„s^2, [M/H] = -0.995, C/O = 0.674, log(Kzz) = 3.879\n",
      "#--------------------------------------------------------------------------------------------------------#\n"
     ]
    }
   ],
   "source": [
    "# Uses EMCEE's discard tool, finds the best parameters, and finds the uncertainties from the simulation\n",
    "flat_samples = sampler.get_chain(discard=discard, thin=15, flat=True)\n",
    "best_fit_params = []\n",
    "for i in range(ndim):\n",
    "    mcmc = np.percentile(flat_samples[:, i], [5, 50, 95])\n",
    "    best_fit_params.append([mcmc[0], mcmc[1], mcmc[2]])\n",
    "\n",
    "# Prints these values\n",
    "fraction_string = f\"{'cm'}\\u2044{'s^2'}\"\n",
    "chi2_final = -0.0001*rsquare(observed_wave, observed_flux, [best_fit_params[0][1], best_fit_params[1][1], best_fit_params[2][1], best_fit_params[3][1], best_fit_params[4][1], best_fit_params[5][1], best_fit_params[6][1]], total_grid)\n",
    "print('#--------------------------------------------------------------------------------------------------------#')\n",
    "print('                     Best Fit Parameters \\u03C72 = ' + str(round((np.median(chi2_final)), 3)))\n",
    "print('#--------------------------------------------------------------------------------------------------------#')\n",
    "print(\"  Best Fit Parameters: Teff = \" + str(round(best_fit_params[0][1], 1)) + 'K, log(g) = ' + str(round(best_fit_params[1][1], 3)) + str(fraction_string) + ', [M/H] = ' + str(round(best_fit_params[2][1], 3)) + ', C/O = ' + str(round(best_fit_params[3][1], 3)) + ', log(Kzz) = ' + str(round(best_fit_params[4][1], 3)))\n",
    "print('#--------------------------------------------------------------------------------------------------------#')\n",
    "print(\"    Lower Estimate: Teff = \" + str(round(best_fit_params[0][0], 1)) + 'K, log(g) = ' + str(round(best_fit_params[1][0], 3)) + str(fraction_string) + ', [M/H] = ' + str(round(best_fit_params[2][0], 3)) + ', C/O = ' + str(round(best_fit_params[3][0], 3)) + ', log(Kzz) = ' + str(round(best_fit_params[4][0], 3)))\n",
    "print(\"    Upper Estimate: Teff = \" + str(round(best_fit_params[0][2], 1)) + 'K, log(g) = ' + str(round(best_fit_params[1][2], 3)) + str(fraction_string) + ', [M/H] = ' + str(round(best_fit_params[2][2], 3)) + ', C/O = ' + str(round(best_fit_params[3][2], 3)) + ', log(Kzz) = ' + str(round(best_fit_params[4][2], 3)))\n",
    "print('#--------------------------------------------------------------------------------------------------------#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots the Comparison of the Spectrum, Walker Space, and a Corner Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------------------------------------- #\n",
    "# Set plot font and create main figure with subplots\n",
    "import os\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "fig, (ax_chain, ax_diff) = plt.subplots(2, 1, figsize=(12, 10), gridspec_kw={'height_ratios': [2, 1]})\n",
    "\n",
    "# Parameter chain plotting and CSV export\n",
    "samples = sampler.get_chain()\n",
    "labels = [\"$T_{eff}$\", \"log(g)\", \"[M/H]\", 'C/O', 'log(Kzz)', 'âˆ†F', 'âˆ†Î»']\n",
    "params_names = ['teff', 'logg', 'MH', 'CO', 'logKzz', 'delta_flux', 'delta_micron']\n",
    "\n",
    "for i, (name, label) in enumerate(zip(params_names, labels)):\n",
    "    flattened_array = samples[:, :, i].reshape((steps, walkers))\n",
    "    df = pd.DataFrame(flattened_array, columns=[f'WALKER_{j+1}' for j in range(walkers)])\n",
    "    df.to_csv(f'Output/{output_file}_parameter_{name}_ELFOWL.csv', index=False)\n",
    "\n",
    "# Model flux calculation\n",
    "target_co = [0.5, 1.0, 1.5, 2.5]\n",
    "target_kzz = [2, 4, 7, 8, 9]\n",
    "target_logg = [4, 4.25, 4.5, 4.75, 5, 5.25, 5.5]\n",
    "target_metal = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "grid_parm = [\n",
    "    *closest_hundreds(best_fit_params[0][1]),\n",
    "    *closest_bounds(best_fit_params[1][1], target_logg),\n",
    "    *closest_bounds(best_fit_params[2][1], target_metal),\n",
    "    *closest_bounds(best_fit_params[3][1], target_co),\n",
    "    *closest_bounds(best_fit_params[4][1], target_kzz)\n",
    "]\n",
    "\n",
    "bounds = np.array([\n",
    "    [int(grid_parm[0]), grid_parm[2], grid_parm[4], grid_parm[6], grid_parm[8]],\n",
    "    [int(grid_parm[1]), grid_parm[3], grid_parm[5], grid_parm[7], grid_parm[9]]\n",
    "])\n",
    "\n",
    "# Define grid points\n",
    "grid_points = np.array([\n",
    "    [temp, logg, metal, co, kzz]\n",
    "    for temp in bounds[:, 0]\n",
    "    for logg in bounds[:, 1]\n",
    "    for metal in bounds[:, 2]\n",
    "    for co in bounds[:, 3]\n",
    "    for kzz in bounds[:, 4]\n",
    "])\n",
    "\n",
    "indices = np.array([np.where(np.all(point_grid == point, axis=1))[0][0] for point in grid_points])\n",
    "model_fluxes = value_grid[indices]\n",
    "\n",
    "model_flux = griddata(grid_points, model_fluxes, (best_fit_params[0], best_fit_params[1][1], best_fit_params[2][1], best_fit_params[3][1], best_fit_params[4][1]), method='linear', rescale=True)\n",
    "\n",
    "# Plot observed and model spectra\n",
    "ax_chain.plot(observed_wave, observed_flux, lw=2, c='k', label='Observed')\n",
    "\n",
    "flux_diff = np.subtract(observed_flux, model_flux[0])\n",
    "ax_diff.axhline(0, c='k', lw=2)\n",
    "ax_diff.plot(observed_wave, flux_diff, c='fuchsia')\n",
    "\n",
    "model_flux = gaussian_filter1d(model_flux, 1.4)\n",
    "ax_chain.plot(observed_wave, model_flux[0], lw=5, c='fuchsia', label='Best Fit Model', alpha=0.6)\n",
    "\n",
    "# Save the fitted spectra\n",
    "df = pd.DataFrame({'WAVELENGTH': observed_wave, 'FLUX': model_flux[0]})\n",
    "df.to_csv(f'Output/{output_file}_fitted-spectra_ELFOWL.csv', index=False)\n",
    "\n",
    "# Customize plot appearance\n",
    "ax_chain.set_ylabel('Flux log$_{10}$(erg/s/cm$^{2}$/Ã…)', fontsize=25)\n",
    "ax_diff.set_xlabel('Wavelength (Âµm)', fontsize=25)\n",
    "ax_diff.set_ylabel('Î”Flux', fontsize=25)\n",
    "for ax in [ax_chain, ax_diff]:\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(which='minor', width=1, length=3, labelsize=10)\n",
    "    ax.tick_params(which='major', width=2, length=6, labelsize=10)\n",
    "ax_chain.tick_params(axis='x', labelsize=12)\n",
    "ax_chain.tick_params(axis='y', labelsize=12, labelrotation=45)\n",
    "ax_diff.tick_params(axis='x', labelsize=12)\n",
    "ax_diff.tick_params(axis='y', labelsize=12, labelrotation=45)\n",
    "ax_chain.legend(prop={'size': 20})\n",
    "ax_chain.set_ylim(-0.1, 1.1)\n",
    "\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.savefig('Output/figure1.png', dpi=200)\n",
    "plt.close('all')\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------- #\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.figure(figsize=(5, 5))\n",
    "upper_error_t, lower_error_t = round(best_fit_params[0][2] - best_fit_params[0][1], 1), round(best_fit_params[0][1] - best_fit_params[0][0], 1)\n",
    "upper_error_g, lower_error_g = round(best_fit_params[1][2] - best_fit_params[1][1], 2), round(best_fit_params[1][1] - best_fit_params[1][0], 2)\n",
    "upper_error_m, lower_error_m = round(best_fit_params[2][2] - best_fit_params[2][1], 2), round(best_fit_params[2][1] - best_fit_params[2][0], 2)\n",
    "upper_error_c, lower_error_c = round(best_fit_params[3][2] - best_fit_params[3][1], 2), round(best_fit_params[3][1] - best_fit_params[3][0], 2)\n",
    "upper_error_k, lower_error_k = round(best_fit_params[4][2] - best_fit_params[4][1], 2), round(best_fit_params[4][1] - best_fit_params[4][0], 2)\n",
    "\n",
    "# Makes the limits for the corner plot\n",
    "limits = [(best_fit_params[0][0] - (lower_error_t/2), best_fit_params[0][2] + (upper_error_t/2)), \n",
    "          (best_fit_params[1][0] - (lower_error_g/2), best_fit_params[1][2] + (upper_error_g/2)), \n",
    "          (best_fit_params[2][0] - (lower_error_m/2), best_fit_params[2][2] + (upper_error_m/2)), \n",
    "          (best_fit_params[3][0] - (lower_error_c/2), best_fit_params[3][2] + (upper_error_c/2)), \n",
    "          (best_fit_params[4][0] - (lower_error_k/2), best_fit_params[4][2] + (upper_error_k/2))]\n",
    "\n",
    "# Define your filtered labels and truths\n",
    "num_params_to_display = len(labels) - 2\n",
    "filtered_labels = labels[:num_params_to_display]\n",
    "filtered_truths = [best_fit_params[i][1] for i in range(num_params_to_display)]\n",
    "\n",
    "# Create a mapping of labels to their index\n",
    "label_to_index = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "# Determine indices of the parameters to keep\n",
    "indices_to_keep = [label_to_index[label] for label in filtered_labels]\n",
    "\n",
    "# Filter the limits list to include only the relevant ranges\n",
    "filtered_limits = [limits[i] for i in indices_to_keep]\n",
    "\n",
    "# Filter flat_samples to include only relevant parameters\n",
    "filtered_samples = np.array(flat_samples)[:, indices_to_keep]\n",
    "\n",
    "# Create the corner plot\n",
    "corner_fig = corner.corner(\n",
    "    filtered_samples,\n",
    "    labels=filtered_labels,\n",
    "    truths=filtered_truths,\n",
    "    truth_color='fuchsia',\n",
    "    title_fmt='.2f',\n",
    "    title_kwargs={'fontsize': 25},\n",
    "    plot_contours=True,\n",
    "    label_kwargs={'fontsize': 25},\n",
    "    quantiles=[0.05, 0.5, 0.95],\n",
    "    use_math_text=True,\n",
    "    range=filtered_limits\n",
    ")\n",
    "\n",
    "# Sets the titles for the corner plots\n",
    "titles = [fr'$Teff = {round(best_fit_params[0][1], 1)}^{{+{upper_error_t}}}_{{-{lower_error_t}}}$',\n",
    "          fr'$log(g) = {round(best_fit_params[1][1], 2)}^{{+{upper_error_g}}}_{{-{lower_error_g}}}$', \n",
    "           fr'$[M/H] = {(round(best_fit_params[2][1], 2))}^{{+{upper_error_m}}}_{{-{lower_error_m}}}$', \n",
    "           fr'$C/O = {(round(best_fit_params[3][1], 2))}^{{+{upper_error_c}}}_{{-{lower_error_c}}}$', \n",
    "           fr'$log(Kzz) = {(round(best_fit_params[4][1], 2))}^{{+{upper_error_k}}}_{{-{lower_error_k}}}$']\n",
    "list = [0, 6, 12, 18, 24]\n",
    "for i in range(len(list)):\n",
    "    ax = corner_fig.axes[list[i]]\n",
    "    ax.set_title(titles[i], fontsize=12)\n",
    "    \n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0.1, hspace=0.1)    \n",
    "plt.savefig('Output/figure2.png', dpi = 200)\n",
    "plt.close('all')\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------- #\n",
    "# Combine figures\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 8), gridspec_kw={'width_ratios': [1.25, 1]})\n",
    "\n",
    "# Display scatter and corner plot images\n",
    "scatter_img = plt.imread(\"Output/figure1.png\")\n",
    "axs[0].imshow(scatter_img)\n",
    "axs[0].axis('off')\n",
    "os.remove(\"Output/figure1.png\")\n",
    "\n",
    "corner_img = plt.imread(\"Output/figure2.png\")\n",
    "axs[1].imshow(corner_img)\n",
    "axs[1].axis('off')\n",
    "os.remove(\"Output/figure2.png\")\n",
    "\n",
    "plt.subplots_adjust(wspace=-0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'Output/{output_file}_ELFOWL.pdf', dpi=500)\n",
    "plt.close('all')\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the results\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------- #\n",
    "samples = sampler.get_chain()\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(ndim, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Plot each parameter\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    for j in range(nwalkers):\n",
    "        ax.plot(samples[:, :, i].T[j], lw=1, color='k', alpha=0.5)\n",
    "    ax.set_ylabel(f\"Parameter {i+1}\")\n",
    "    ax.set_xlim(0, samples.shape[0])\n",
    "\n",
    "# Label x-axis only for the last subplot\n",
    "axes[-1].set_xlabel(\"Step number\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'Output/{output_file}_ELFOWL_STEPS.pdf')\n",
    "plt.close('all')\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ðŸŽ¬ END OF ELFCASTL ðŸŽ¬**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
